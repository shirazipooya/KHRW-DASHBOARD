{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from Assets import jalali\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load Database\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "xls = pd.ExcelFile('Database/HydrographData.xlsx')\n",
    "Data = pd.read_excel(xls, sheet_name='Data')\n",
    "GeoInfo = pd.read_excel(xls, sheet_name='GeoInfo').drop(['INDEX'], axis=1)\n",
    "\n",
    "## GeoInfo\n",
    "COLs = ['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME']\n",
    "GeoInfo[COLs] = GeoInfo[COLs].apply(lambda x: x.str.rstrip())\n",
    "GeoInfo[COLs] = GeoInfo[COLs].apply(lambda x: x.str.lstrip())\n",
    "GeoInfo[COLs] = GeoInfo[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "GeoInfo[COLs] = GeoInfo[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "GeoInfo[COLs] = GeoInfo[COLs].apply(lambda x: x.str.replace('ك', 'ک'))\n",
    "\n",
    "## Data\n",
    "COLs = ['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME']\n",
    "Data[COLs] = Data[COLs].apply(lambda x: x.str.rstrip())\n",
    "Data[COLs] = Data[COLs].apply(lambda x: x.str.lstrip())\n",
    "Data[COLs] = Data[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "Data[COLs] = Data[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "Data[COLs] = Data[COLs].apply(lambda x: x.str.replace('ك', 'ک'))\n",
    "\n",
    "\n",
    "# Load GeoDatabase\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Well Points\n",
    "gdf = gpd.read_file(\"GeoDatabase/Wells_Selected.geojson\").drop(['INDEX'], axis=1)\n",
    "gdf = gdf.set_crs(\"EPSG:32640\", allow_override=True)\n",
    "COLs = ['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME']\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ك', 'ک'))\n",
    "\n",
    "## Boundary\n",
    "mask = gpd.read_file(\"GeoDatabase/Aquifers_Selected.geojson\")\n",
    "mask = mask.set_crs(\"EPSG:32640\", allow_override=True)\n",
    "COLs = ['AQ_NAME', 'MA_NAME']\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ك', 'ک'))\n",
    "\n",
    "\n",
    "# Convert Date\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Data[\"DATE_GREGORIAN_RAW\"] = Data[\"DATE_GREGORIAN_RAW\"].apply(pd.to_datetime)\n",
    "\n",
    "Data['DATE_CHECK'] = np.where(\n",
    "    Data[\"DATE_PERSIAN_RAW\"].isna(),\n",
    "    np.where(\n",
    "        Data[\"DATE_GREGORIAN_RAW\"].isna(),\n",
    "        np.NaN,\n",
    "        \"G\"\n",
    "    ),\n",
    "    \"P\"  \n",
    ")\n",
    "\n",
    "Data['DATE_PERSIAN_RAW'] = Data.apply(\n",
    "    lambda x: jalali.Gregorian(x[\"DATE_GREGORIAN_RAW\"].date()).persian_string() if x[\"DATE_CHECK\"] == \"G\" else x[\"DATE_PERSIAN_RAW\"], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "Data['DATE_GREGORIAN_RAW'] = Data.apply(\n",
    "    lambda x: jalali.Persian(x[\"DATE_PERSIAN_RAW\"]).gregorian_string() if x[\"DATE_CHECK\"] == \"P\" else x[\"DATE_GREGORIAN_RAW\"], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "Data[\"DATE_GREGORIAN_RAW\"] = Data[\"DATE_GREGORIAN_RAW\"].apply(pd.to_datetime)\n",
    "\n",
    "\n",
    "Data.drop(['DATE_CHECK'], axis=1, inplace=True)\n",
    "\n",
    "Data.sort_values(\n",
    "    by=[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_GREGORIAN_RAW\"], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Convert To Day 15\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def convert_to_day_15(data, date_type=\"persian\"):\n",
    "    \n",
    "    data = data.reset_index(drop=True)\n",
    "            \n",
    "    df = data[[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\"]]\n",
    "    \n",
    "    if date_type == \"gregorian\":\n",
    "        df[\"DATE_GREGORIAN\"] = data.DATE_GREGORIAN_RAW.apply(pd.to_datetime)\n",
    "        df[\"DATE_PERSIAN\"] = list(\n",
    "            map(\n",
    "                lambda i: jalali.Gregorian(i.date()).persian_string(),\n",
    "                df[\"DATE_GREGORIAN\"]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    elif date_type == \"persian\":\n",
    "        df[\"DATE_PERSIAN\"] = data.DATE_PERSIAN_RAW\n",
    "        df[\"DATE_GREGORIAN\"] = list(\n",
    "            map(\n",
    "                lambda i: jalali.Persian(i).gregorian_string(),\n",
    "                df[\"DATE_PERSIAN\"]\n",
    "            )\n",
    "        )\n",
    "        df[\"DATE_GREGORIAN\"] = df[\"DATE_GREGORIAN\"].apply(pd.to_datetime)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    df[\"VALUE\"] = data.WATER_TABLE_RAW \n",
    "           \n",
    "    df[\"DELTA_DAY\"] = df[\"DATE_GREGORIAN\"].diff().dt.days\n",
    "    \n",
    "    df[\"DATE_PERSIAN_NEW\"] = list(\n",
    "        map(\n",
    "            lambda i: f\"{int(i.split('-')[0])}-{int(i.split('-')[1])}-{15}\",\n",
    "            df[\"DATE_PERSIAN\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    df[\"DATE_GREGORIAN_NEW\"] = list(\n",
    "        map(\n",
    "            lambda i: jalali.Persian(i).gregorian_string(),\n",
    "            df[\"DATE_PERSIAN_NEW\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    df[\"DATE_GREGORIAN_NEW\"] = df[\"DATE_GREGORIAN_NEW\"].apply(pd.to_datetime)\n",
    "    \n",
    "    df[\"VALUE_NEW\"] = df[\"VALUE\"]\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    A.append(df[\"VALUE\"][0])\n",
    "    \n",
    "    for i in range(1, len(df) - 1):\n",
    "        if int(df[\"DATE_PERSIAN\"][i].split('-')[2]) >= 15:\n",
    "            NEW_VALUE = df[\"VALUE\"][i-1] + ((((df[\"DATE_GREGORIAN_NEW\"][i] - df[\"DATE_GREGORIAN\"][i-1]).days) / ((df[\"DATE_GREGORIAN\"][i] - df[\"DATE_GREGORIAN\"][i-1]).days)) * (df[\"VALUE\"][i] - df[\"VALUE\"][i-1]))\n",
    "            A.append(NEW_VALUE)\n",
    "        else:\n",
    "            NEW_VALUE = df[\"VALUE\"][i] + ((((df[\"DATE_GREGORIAN_NEW\"][i] - df[\"DATE_GREGORIAN\"][i]).days) / ((df[\"DATE_GREGORIAN\"][i+1] - df[\"DATE_GREGORIAN\"][i]).days)) * (df[\"VALUE\"][i+1] - df[\"VALUE\"][i]))\n",
    "            A.append(NEW_VALUE)\n",
    "    \n",
    "    A.append(df[\"VALUE\"][len(df) - 1])\n",
    "            \n",
    "    df[\"VALUE_NEW\"] = A\n",
    "        \n",
    "    return df\n",
    "\n",
    "Data = Data.drop_duplicates(\n",
    "    subset=['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME', 'DATE_GREGORIAN_RAW'],\n",
    "    keep='last'\n",
    ")\n",
    "\n",
    "Data.dropna(\n",
    "    subset=[\"WATER_TABLE_RAW\"],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "Data.reset_index(\n",
    "    drop=True,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "wt_date_converted = Data.groupby([\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\"])\\\n",
    "    .apply(convert_to_day_15)\\\n",
    "        .reset_index(drop=True)[[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_PERSIAN\", \"DATE_PERSIAN_NEW\", \"DATE_GREGORIAN\", \"DATE_GREGORIAN_NEW\", \"VALUE_NEW\"]]\n",
    "\n",
    "wt_date_converted.columns = [\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_PERSIAN_RAW\", \"DATE_PERSIAN\", \"DATE_GREGORIAN_RAW\",\"DATE_GREGORIAN\", \"WATER_TABLE\"]\n",
    "\n",
    "Data = Data.merge(\n",
    "    right=wt_date_converted,\n",
    "    how=\"left\",\n",
    "    on=[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_PERSIAN_RAW\", \"DATE_GREGORIAN_RAW\"]\n",
    ")\n",
    "\n",
    "Data = Data.drop_duplicates(\n",
    "    subset=['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME', 'DATE_GREGORIAN'],\n",
    "    keep='last'\n",
    ")\n",
    "\n",
    "\n",
    "# Gap Filling\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_date_day15(min, max):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        min ([type]): [description]\n",
    "        max ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    min_list = list(map(lambda x: int(x), min.split(\"-\")))\n",
    "    max_list = list(map(lambda x: int(x), max.split(\"-\")))\n",
    "    for y in range(min_list[0], max_list[0] + 1):\n",
    "        for m in range(1, 13):\n",
    "            result.append(f\"{y}-{m}-15\")\n",
    "\n",
    "    result = pd.DataFrame(\n",
    "        {\"DATE_PERSIAN\" : result}\n",
    "    )\n",
    "    result['DATE_GREGORIAN'] = result.apply(\n",
    "        lambda x: jalali.Persian(x[\"DATE_PERSIAN\"]).gregorian_string(), \n",
    "        axis=1\n",
    "    )\n",
    "    result[\"DATE_GREGORIAN\"] = result[\"DATE_GREGORIAN\"].apply(pd.to_datetime)\n",
    "    result = result[result[\"DATE_GREGORIAN\"] >= pd.to_datetime(jalali.Persian(min).gregorian_string())]\n",
    "    result = result[result[\"DATE_GREGORIAN\"] <= pd.to_datetime(jalali.Persian(max).gregorian_string())]\n",
    "    result[\"DATE_GREGORIAN\"] = result[\"DATE_GREGORIAN\"].apply(pd.to_datetime)  \n",
    "    return result\n",
    "\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "for mn in list(Data[\"MAHDOUDE_NAME\"].unique()):\n",
    "    df_mn = Data[(Data[\"MAHDOUDE_NAME\"] == mn)]\n",
    "    \n",
    "    for an in list(df_mn[\"AQUIFER_NAME\"].unique()):\n",
    "        df_mn_an = df_mn[(df_mn[\"AQUIFER_NAME\"] == an)]\n",
    "        \n",
    "        for ln in list(df_mn_an[\"LOCATION_NAME\"].unique()):\n",
    "            df_mn_an_ln = df_mn_an[(df_mn_an[\"LOCATION_NAME\"] == ln)]\n",
    "            \n",
    "            df_mn_an_ln = df_mn_an_ln.reset_index(drop=False)\n",
    "            \n",
    "            date = create_date_day15(\n",
    "                min = df_mn_an_ln.DATE_PERSIAN.min(),\n",
    "                max = df_mn_an_ln.DATE_PERSIAN.max()\n",
    "            ).reset_index(drop=False).sort_values(by=[\"DATE_GREGORIAN\"])\n",
    "            \n",
    "            df = date.merge(\n",
    "                df_mn_an_ln,\n",
    "                how=\"left\",\n",
    "                on=[\"DATE_PERSIAN\", \"DATE_GREGORIAN\"]\n",
    "            )\n",
    "            \n",
    "            df[\"MAHDOUDE_NAME\"] = mn\n",
    "            df[\"AQUIFER_NAME\"] = an\n",
    "            df[\"LOCATION_NAME\"] = ln\n",
    "            df[\"STORAGE_COEFFICIENT_LOCATION\"] = df[\"STORAGE_COEFFICIENT_LOCATION\"].unique()[0]\n",
    "            \n",
    "            df = df[[\n",
    "                \"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\",\n",
    "                \"DATE_GREGORIAN\", \"DATE_PERSIAN\",\n",
    "                \"WATER_TABLE\", \"STORAGE_COEFFICIENT_LOCATION\", \"THISSEN_LOCATION\", \"THISSEN_AQUIFER\",\n",
    "                \"DATA_STATE\", \"DATE_GREGORIAN_RAW\", \"DATE_PERSIAN_RAW\", \"WATER_TABLE_RAW\"\t\n",
    "            ]]\n",
    "\n",
    "            tmp = pd.concat([tmp, df], axis=0)\n",
    "\n",
    "Data = tmp.copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "Data['DATE_GREGORIAN_RAW'].fillna(Data['DATE_GREGORIAN'], inplace=True)\n",
    "Data['DATE_PERSIAN_RAW'].fillna(Data['DATE_PERSIAN'], inplace=True)\n",
    "\n",
    "\n",
    "del tmp\n",
    "\n",
    "Data[['YEAR', 'MONTH', 'DAY']] = Data['DATE_PERSIAN_RAW'].str.split('-', 2, expand=True)\n",
    "Data[\"YEAR\"] = Data[\"YEAR\"].str.zfill(4)\n",
    "Data[\"MONTH\"] = Data[\"MONTH\"].str.zfill(2)\n",
    "Data[\"DAY\"] = Data[\"DAY\"].str.zfill(2)\n",
    "Data['DATE_PERSIAN_RAW'] = Data[\"YEAR\"] + \"-\" + Data[\"MONTH\"] + \"-\" + Data[\"DAY\"]\n",
    "\n",
    "\n",
    "Data = Data[\n",
    "    [\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_GREGORIAN_RAW\", \"DATE_PERSIAN_RAW\", \"WATER_TABLE_RAW\", \"STORAGE_COEFFICIENT_LOCATION\", \"THISSEN_LOCATION\", \"THISSEN_AQUIFER\", \"DATA_STATE\"]\n",
    "]\n",
    "\n",
    "Data = Data.sort_values(by=[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_GREGORIAN_RAW\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "data = Data.copy()\n",
    "# data = Data[Data[\"MAHDOUDE_NAME\"].isin([\"گیسور\"])]\n",
    "# data = data[data[\"AQUIFER_NAME\"].isin([\"گیسور\"])]\n",
    "# data = data[data[\"LOCATION_NAME\"].isin([\"کهنه عامر\"])]\n",
    "data = data.sort_values(by=[\"MAHDOUDE_NAME\", \"AQUIFER_NAME\", \"LOCATION_NAME\", \"DATE_GREGORIAN_RAW\"]).reset_index(drop=True)\n",
    "\n",
    "data[\"DIFF\"] = data[\"WATER_TABLE_RAW\"].diff().abs()\n",
    "data[\"DIFF_MEAN\"] = data[\"DIFF\"].rolling(6).mean()\n",
    "data[\"CHECK_METHOD_1\"] = data[\"DIFF\"] > data[\"DIFF_MEAN\"]\n",
    "\n",
    "data.to_csv(\"dddl.csv\")\n",
    "\n",
    "data[\"SHIFT_DATE\"] = data[\"DATE_GREGORIAN_RAW\"].shift(periods=1)\n",
    "data[\"DIFF_DATE\"] = (data[\"DATE_GREGORIAN_RAW\"] - data[\"SHIFT_DATE\"]).dt.days.abs()\n",
    "data[\"DERIVATIV\"] = (data[\"DIFF\"] / data[\"DIFF_DATE\"]) * 100\n",
    "data[\"CHECK_METHOD_2\"] = data[\"DERIVATIV\"] > 2\n",
    "\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# CREATE DATABASE\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import sqlite3\n",
    "PATH_DB_GROUNDWATER_RAW_DATA = '../../Assets/Database/groundwater_raw_data.db'\n",
    "DB_GROUNDWATER_RAW_DATA = sqlite3.connect(PATH_DB_GROUNDWATER_RAW_DATA, check_same_thread=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# WRITE DATABASE\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "Data[\"WATER_TABLE_MODIFY\"] = Data[\"WATER_TABLE_RAW\"].replace({'0':np.nan, 0:np.nan})\n",
    "\n",
    "Data.to_sql(\n",
    "    name=\"GROUNDWATER_DATA\",\n",
    "    con=DB_GROUNDWATER_RAW_DATA,\n",
    "    if_exists=\"replace\"\n",
    ")\n",
    "\n",
    "GeoInfo.to_sql(\n",
    "    name=\"GEOINFO_DATA\",\n",
    "    con=DB_GROUNDWATER_RAW_DATA,\n",
    "    if_exists=\"replace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from Assets import jalali\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load GeoDatabase\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Well Points\n",
    "gdf = gpd.read_file(\"GeoDatabase/Wells_Selected.geojson\").drop(['INDEX'], axis=1)\n",
    "gdf = gdf.set_crs(\"EPSG:32640\", allow_override=True)\n",
    "COLs = ['MAHDOUDE_NAME', 'AQUIFER_NAME', 'LOCATION_NAME']\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "gdf[COLs] = gdf[COLs].apply(lambda x: x.str.replace('ك', 'ک'))\n",
    "\n",
    "## Boundary\n",
    "mask = gpd.read_file(\"GeoDatabase/Aquifers_Selected.geojson\")\n",
    "mask = mask.set_crs(\"EPSG:32640\", allow_override=True)\n",
    "COLs = ['AQ_NAME', 'MA_NAME']\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ي','ی'))\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ئ','ی'))\n",
    "mask[COLs] = mask[COLs].apply(lambda x: x.str.replace('ك', 'ک'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_file[\"features\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "geodf = mask.copy()\n",
    "\n",
    "j_file = json.loads(geodf.to_json())\n",
    "\n",
    "for feature in j_file[\"features\"]:\n",
    "    feature['id'] = feature['properties']['AQ_NAME']\n",
    "\n",
    "# fig = px.choropleth_mapbox(\n",
    "#     data_frame=geodf,\n",
    "#     geojson=j_file,\n",
    "#     locations='MA_CODE',\n",
    "#     opacity=0.4,\n",
    "# )\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    geodf, \n",
    "    geojson=j_file,\n",
    "    locations='AQ_NAME',\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    opacity=0.5\n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scattermapbox(\n",
    "#         lat=data.Y_Decimal,\n",
    "#         lon=data.X_Decimal,\n",
    "#         mode='markers',\n",
    "#         marker=go.scattermapbox.Marker(size=8),\n",
    "#         text=data[\"Well_Name\"],\n",
    "#         hoverinfo='text',\n",
    "#         hovertemplate='<span style=\"color:white;\">%{text}</span><extra></extra>'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scattermapbox(\n",
    "#         lat=selected_wells.Y_Decimal,\n",
    "#         lon=selected_wells.X_Decimal,\n",
    "#         mode='markers',\n",
    "#         marker=go.scattermapbox.Marker(\n",
    "#             size=10,\n",
    "#             color='green'\n",
    "#         ),\n",
    "#         text=selected_wells[\"Well_Name\"],\n",
    "#         hoverinfo='text',\n",
    "#         hovertemplate='<b>%{text}</b><extra></extra>'\n",
    "#     ), \n",
    "# )\n",
    "    \n",
    "# fig.update_layout(\n",
    "#     mapbox = {\n",
    "#         'style': \"stamen-terrain\",\n",
    "#         'zoom': 5,\n",
    "#     },\n",
    "#     showlegend = False,\n",
    "#     hovermode='closest',\n",
    "#     margin = {'l':0, 'r':0, 'b':0, 't':0}\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    df, \n",
    "    geojson=counties,\n",
    "    locations='fips',\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    opacity=0.5\n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=263dfb2e-14c8-403a-b2fd-78303494e181 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('263dfb2e-14c8-403a-b2fd-78303494e181').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>DIFF</th>\n",
       "      <th>DIFF_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "    X  DIFF  DIFF_MEAN\n",
       "0   0   NaN        NaN\n",
       "1   5   5.0        NaN\n",
       "2   9   4.0   5.000000\n",
       "3   4   5.0   4.500000\n",
       "4   1   3.0   4.666667\n",
       "5   2   1.0   4.000000\n",
       "6   6   4.0   3.000000\n",
       "7   7   1.0   2.666667\n",
       "8   7   0.0   2.000000\n",
       "9   2   5.0   1.666667\n",
       "10  0   2.0   2.000000\n",
       "11  9   9.0   2.333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = pd.DataFrame(\n",
    "    {\n",
    "        \"X\": [0, 5, 9, 4, 1, 2, 6, 7, 7, 2, 0, 9]\n",
    "    }\n",
    ")\n",
    "\n",
    "A[\"DIFF\"] = A[\"X\"].diff().abs()\n",
    "\n",
    "\n",
    "A[\"DIFF_MEAN\"] = A[\"DIFF\"].rolling(3, min_periods=1).mean().shift(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94bafb05d58ff56845a937184a4f5ebe1df376fd286d6df80b03e72709963184"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
